{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import re\n",
    "\n",
    "def parse_date(date):\n",
    "    if len(date.split('.')) > 1 :\n",
    "        dates = date.split(' ')\n",
    "        dates[1] = re.sub(\"\\D\", \"\", dates[1])\n",
    "        dates[3] = dates[3].split('.')[0]\n",
    "        date = \" \".join(dates)\n",
    "        date = datetime.strptime(date, '%B %d %Y, %H:%M:%S')\n",
    "    else:\n",
    "        date = date[date.find(\" \")+1:]\n",
    "        date = datetime.strptime(date, '%b %d %H:%M:%S %Y')\n",
    "\n",
    "    tzinfo = tz.gettz('Asia/Taipei')\n",
    "    return date.replace(tzinfo=tzinfo).isoformat()\n",
    "\n",
    "dates = [\n",
    "    'December 9th 2016, 22:24:35.000',\n",
    "    'Wed Oct 5 20:53:22 2016'\n",
    "]\n",
    "[parse_date(date) for date in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping (Blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from elasticsearch_dsl import DocType, Date, Integer, Keyword, Text, connections\n",
    "\n",
    "# # Define a default Elasticsearch client\n",
    "# connections.create_connection(hosts=['13.78.14.166'])\n",
    "\n",
    "# class Article(DocType):\n",
    "#     title = Text(analyzer='snowball', fields={'raw': Keyword()})\n",
    "#     body = Text(analyzer='snowball')\n",
    "#     tags = Keyword()\n",
    "#     published_from = Date()\n",
    "#     lines = Integer()\n",
    "\n",
    "#     class Meta:\n",
    "#         index = 'blog'\n",
    "\n",
    "#     def save(self, ** kwargs):\n",
    "#         self.lines = len(self.body.split())\n",
    "#         return super(Article, self).save(** kwargs)\n",
    "\n",
    "#     def is_published(self):\n",
    "#         return datetime.now() > self.published_from\n",
    "\n",
    "# # create the mappings in elasticsearch\n",
    "# Article.init()\n",
    "\n",
    "# # create and save and article\n",
    "# article = Article(meta={'id': 42}, title='Hello world!', tags=['test'])\n",
    "# article.body = ''' looong text '''\n",
    "# article.published_from = datetime.now()\n",
    "# article.save()\n",
    "\n",
    "# article = Article.get(id=42)\n",
    "# print(article.is_published())\n",
    "\n",
    "# # Display cluster health\n",
    "# print(connections.get_connection().cluster.health())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping (Post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from elasticsearch_dsl import DocType, Date, Nested, Boolean, \\\n",
    "#     analyzer, InnerDoc, Completion, Keyword, Text\n",
    "\n",
    "# html_strip = analyzer('html_strip',\n",
    "#     tokenizer=\"standard\",\n",
    "#     filter=[\"standard\", \"lowercase\", \"stop\", \"snowball\"],\n",
    "#     char_filter=[\"html_strip\"]\n",
    "# )\n",
    "\n",
    "# class Comment(InnerDoc):\n",
    "#     author = Text(fields={'raw': Keyword()})\n",
    "#     content = Text(analyzer='snowball')\n",
    "#     created_at = Date(default_timezone='Asia/Taipei')\n",
    "\n",
    "#     def age(self):\n",
    "#         return datetime.now() - self.created_at\n",
    "\n",
    "# class Post(DocType):\n",
    "#     title = Text()\n",
    "#     title_suggest = Completion()\n",
    "#     created_at = Date()\n",
    "#     published = Boolean()\n",
    "#     category = Text(\n",
    "#         analyzer=html_strip,\n",
    "#         fields={'raw': Keyword()}\n",
    "#    )\n",
    "\n",
    "# # 1  city.raw 字段是 city 字段的 keyword 类型字段\n",
    "# # 2  city 字段将被当做 full text 进行搜索\n",
    "# # 34 city.raw 可用于排序和聚合\n",
    "\n",
    "#     comments = Nested(Comment)\n",
    "\n",
    "#     class Meta:\n",
    "#         index = 'blog'\n",
    "\n",
    "#     def add_comment(self, author, content):\n",
    "#         self.comments.append(Comment(author=author, content=content, created_at=datetime.now()))\n",
    "\n",
    "#     def save(self, ** kwargs):\n",
    "#         self.created_at = datetime.now()\n",
    "#         return super().save(** kwargs)\n",
    "    \n",
    "\n",
    "# first = Post(title='My First Blog Post, yay!', published=True)\n",
    "# first.category = ['everything', 'nothing']\n",
    "# first.meta.id = 55\n",
    "# first.add_comment('me', 'This is nice!')\n",
    "# first.add_comment('me', 'dfsdfsf!')\n",
    "# first.add_comment('me', 'asdfasdfasdfasd!')\n",
    "\n",
    "# first.save()\n",
    "# # first.update(published=True, published_by='me')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping (PTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import connections, DocType, Date, Nested, InnerDoc, Keyword, Text, Ip, Integer\n",
    "from datetime import datetime\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "\n",
    "class Message(InnerDoc):\n",
    "    push_tag = Keyword(ignore_above=256)\n",
    "    push_userid = Keyword(ignore_above=256)\n",
    "    push_content = Keyword(ignore_above=256)\n",
    "    push_ipdatetime = Keyword(ignore_above=256)\n",
    "    \n",
    "\n",
    "class MessageCount(InnerDoc):\n",
    "    all = Integer()\n",
    "    boo = Integer()\n",
    "    count = Integer()\n",
    "    neutral = Integer()\n",
    "    push = Integer()\n",
    "\n",
    "\n",
    "class Article(DocType):\n",
    "    article_id = Keyword(ignore_above=256)\n",
    "    article_title = Text(analyzer='ik_max_word')\n",
    "    author = Text(\n",
    "        analyzer='ik_max_word',\n",
    "        fields={'raw': Keyword(ignore_above=256)}\n",
    "    )\n",
    "    board = Keyword(ignore_above=256)\n",
    "    content = Text(analyzer='ik_max_word')\n",
    "    date = Keyword(ignore_above=256)\n",
    "    date_parsed = Date(default_timezone='Asia/Taipei')\n",
    "    ip = Keyword(ignore_above=256)\n",
    "    message_count = Nested(MessageCount)\n",
    "    messages = Nested(Message)\n",
    "\n",
    "    class Meta:\n",
    "        index = 'test-2018-06'\n",
    "\n",
    "Article.init()\n",
    "        \n",
    "#     def add_message(self, author, content):\n",
    "#         self.message.append(Message(author=author, content=content, created_at=datetime.now()))\n",
    "        \n",
    "#     def add_message_count(self, author, content):\n",
    "#         self.message_count.append(MessageCount(author=author, content=content, created_at=datetime.now()))\n",
    "\n",
    "#     def save(self, ** kwargs):\n",
    "#         self.created_at = datetime.now()\n",
    "#         return super().save(** kwargs)\n",
    "# first = Post(title='My First Blog Post, yay!', published=True)\n",
    "# first.category = ['everything', 'nothing']\n",
    "# first.meta.id = 47\n",
    "# first.add_comment('me', 'This is nice!')\n",
    "# first.save()e\n",
    "# # first.update(published=True, published_by='me')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from elasticsearch_dsl import Search\n",
    "# connections.create_connection(hosts=['13.78.14.166'])\n",
    "# client = Elasticsearch()\n",
    "\n",
    "# s = Search(index=\"test2-2018-06\") \\\n",
    "#     .filter(\"term\", category=\"search\") \\\n",
    "#     .query(\"match\", title=\"感情\")   \\\n",
    "#     .exclude(\"match\", description=\"父母\")\n",
    "\n",
    "# s.aggs.bucket('per_tag', 'terms', field='tags') \\\n",
    "#     .metric('max_lines', 'max', field='lines')\n",
    "\n",
    "# response = s.execute()\n",
    "\n",
    "# for hit in response:\n",
    "#     print(hit.meta.score, hit.title)\n",
    "\n",
    "# for tag in response.aggregations.per_tag.buckets:\n",
    "#     print(tag.key, tag.max_lines.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.786729 [新聞] 〈中部〉福興西瓜節週日登場 三選將齊促\n",
      "11.636682 [新聞] 西瓜也有身份證了 後龍西瓜節週六熱鬧登\n",
      "11.601156 [新聞] 猥褻無極限！爆乳女模開腿露下體破西瓜　\n",
      "11.578627 Re: [問卦] 溪州有什麼特產啊\n",
      "11.570553 [問卦] 有紅西瓜的西瓜汁 為什麼沒小玉西瓜汁？\n",
      "11.45617 Re: [新聞] 【選情初探】民進黨：攻下台北、新北　就\n",
      "11.3582535 [新聞] 國宴西瓜行情佳　花警啟動「護瓜專案」\n",
      "11.352176 [新聞] 馬英九叫賣西瓜 1顆1萬8800元助弱勢\n",
      "11.302748 [問卦] 憾！小X百貨竟然沒賣西瓜刀？\n",
      "11.277501 [ＦＢ] 臺南就要變成綠色爛西瓜市了嗎？\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search, connections\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "board = \"Boy-Girl\"\n",
    "board = \"Gossiping\"\n",
    "\n",
    "# Term 精确\n",
    "# Match 模糊\n",
    "s = Search(index=\"test-2018-06\") \\\n",
    "    .filter(\"term\", board=board) \\\n",
    "    .query(\"match\", content=\"西瓜\")   \\\n",
    "#     .query(\"match\", article_title=\"西瓜 夏天\")\\\n",
    "#     .exclude(\"match\", article_title=\"照片\")\n",
    "\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.meta.score, hit.article_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.533302 [問卦] 姆媽 莫驚驚膽膽大 carcino5566 (致癌物5566)\n",
      "10.394623 [問卦] 姆媽 莫驚驚膽膽大 carcino5566 (致癌物5566)\n",
      "10.228952 [問卦] 這感覺已經不對 我努力在挽回 linm12285219 (beforewe9)\n",
      "10.228952 [問卦] 這感覺已經不對 我努力在挽回 linm12285219 (beforewe9)\n",
      "9.923867 [問卦] 為什麼要趕在冬天之前啊？ doubter (心碎的狐狸寶寶)\n",
      "9.9138365 [問卦] 為什麼要趕在冬天之前啊？ doubter (心碎的狐狸寶寶)\n",
      "9.4249735 [問卦] 學妹好像討厭我了 該怎麼辦？ morgankhs (豪哥)\n",
      "9.379307 [問卦] 誰會輕易地喊賊？ jones921245 (jones)\n",
      "9.317057 [問卦] 這樣是母豬嗎？ iamlittlede (小迪)\n",
      "9.317057 [問卦] 這樣是母豬嗎？ iamlittlede (小迪)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search, connections\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "board = \"Gossiping\"\n",
    "s = Search(index=\"test-2018-06\") \\\n",
    "    .filter(\"term\", board=board) \\\n",
    "    .query(\"match\", content=\"挽回\")  \\\n",
    "#     .query(\"match\", article_title=\"西瓜 夏天\")\\\n",
    "#     .exclude(\"match\", article_title=\"照片\")\n",
    "\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.meta.score, hit.article_title, hit.author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
